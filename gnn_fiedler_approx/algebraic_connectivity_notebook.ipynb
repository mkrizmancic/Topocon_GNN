{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import codetiming\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Loaded torch. Using *{device}* device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from my_graphs_dataset import GraphDataset\n",
    "from algebraic_connectivity_dataset import ConnectivityDataset\n",
    "\n",
    "\n",
    "def load_dataset(selected_graph_sizes, selected_features=[], split=0.8, batch_size=0, seed=42, is_sweep=False):\n",
    "    if selected_graph_sizes is None:\n",
    "        selected_graph_sizes = {\n",
    "            3: -1,\n",
    "            4: -1,\n",
    "            5: -1,\n",
    "            6: -1,\n",
    "            7: -1,\n",
    "            8: -1,\n",
    "            # 9:  100000,\n",
    "            # 10: 100000\n",
    "        }\n",
    "\n",
    "    dataset_config = {\n",
    "        \"name\": \"ConnectivityDataset\",\n",
    "        \"selected_graphs\": str(selected_graph_sizes),\n",
    "        \"split\": split,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"seed\": seed,\n",
    "    }\n",
    "\n",
    "    # Load the dataset.\n",
    "    root = pathlib.Path(os.getcwd()) / \"Dataset\"\n",
    "    graphs_loader = GraphDataset(selection=selected_graph_sizes)\n",
    "    dataset = ConnectivityDataset(root, graphs_loader, selected_features=selected_features)\n",
    "\n",
    "    # General information\n",
    "    if not is_sweep:\n",
    "        print()\n",
    "        print(f\"Dataset: {dataset}:\")\n",
    "        print(\"====================\")\n",
    "        print(f\"Number of graphs: {len(dataset)}\")\n",
    "        print(f\"Number of features: {dataset.num_features}\")\n",
    "\n",
    "    # Store information about the dataset.\n",
    "    dataset_config[\"num_graphs\"] = len(dataset)\n",
    "    features = selected_features if selected_features else dataset.features\n",
    "\n",
    "    # Shuffle and split the dataset.\n",
    "    torch.manual_seed(seed)\n",
    "    dataset = dataset.shuffle()\n",
    "\n",
    "    train_size = round(dataset_config[\"split\"] * len(dataset))\n",
    "    train_dataset = dataset[:train_size]\n",
    "    test_dataset = dataset[train_size:]\n",
    "\n",
    "    if not is_sweep:\n",
    "        print()\n",
    "        print(f\"Number of training graphs: {len(train_dataset)}\")\n",
    "        print(f\"Number of test graphs: {len(test_dataset)}\")\n",
    "\n",
    "    # Batch and load data.\n",
    "    # TODO: Batch size?\n",
    "    batch_size = dataset_config[\"batch_size\"] if dataset_config[\"batch_size\"] > 0 else len(train_dataset)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # type: ignore\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) # type: ignore\n",
    "\n",
    "    train_batch = None\n",
    "    test_batch = None\n",
    "    # If the whole dataset fits in memory, we can use the following lines to get a single large batch.\n",
    "    train_batch = next(iter(train_loader))\n",
    "    test_batch = next(iter(test_loader))\n",
    "\n",
    "    train_data_obj = train_batch if train_batch is not None else train_loader\n",
    "    test_data_obj = test_batch if test_batch is not None else test_loader\n",
    "\n",
    "    if not is_sweep:\n",
    "        print()\n",
    "        print(\"Batches:\")\n",
    "        for step, data in enumerate(train_loader):\n",
    "            print(f\"Step {step + 1}:\")\n",
    "            print(\"=======\")\n",
    "            print(f\"Number of graphs in the current batch: {data.num_graphs}\")\n",
    "            print(data)\n",
    "            print()\n",
    "\n",
    "    return train_data_obj, test_data_obj, dataset_config, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, ReLU\n",
    "from torch_geometric.nn import GCNConv, Sequential\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class MyGCN(torch.nn.Module):\n",
    "    def __init__(self, input_channels, mp_layers):\n",
    "        super(MyGCN, self).__init__()\n",
    "\n",
    "        # Message-passing layers - GCNConv\n",
    "        layers = []\n",
    "        for i, layer_size in enumerate(mp_layers):\n",
    "            if i == 0:\n",
    "                layers.append((GCNConv(input_channels, layer_size), \"x, edge_index -> x\"))\n",
    "            else:\n",
    "                layers.append((GCNConv(mp_layers[i - 1], layer_size), \"x, edge_index -> x\"))\n",
    "            layers.append(ReLU())\n",
    "        self.mp_layers = Sequential(\"x, edge_index\", layers)\n",
    "\n",
    "        # Final readout layer\n",
    "        self.lin = Linear(mp_layers[-1], 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.mp_layers(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_gnns = {x.__name__: x for x in [MyGCN]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrapper for pre-made models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCN, GraphSAGE, GIN, GAT\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "premade_gnns = {x.__name__: x for x in [GCN, GraphSAGE, GIN, GAT]}\n",
    "\n",
    "\n",
    "class GNNWrapper(torch.nn.Module):\n",
    "    def __init__(self, gnn_model, in_channels: int, hidden_channels: int, num_layers: int, **kwargs):\n",
    "        super().__init__()\n",
    "        self.gnn = gnn_model(in_channels, hidden_channels, num_layers, **kwargs)\n",
    "        self.classifier = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.gnn(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "def generate_model(architecture, in_channels, hidden_channels, num_layers):\n",
    "    \"\"\"Generate a Neural Network model based on the architecture and hyperparameters.\"\"\"\n",
    "    # GLOBALS: device, premade_gnns, custom_gnns\n",
    "    if architecture in premade_gnns:\n",
    "        model = GNNWrapper(\n",
    "            gnn_model=premade_gnns[architecture],\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            num_layers=num_layers,\n",
    "        ).to(device)\n",
    "    else:\n",
    "        MyGNN = custom_gnns[architecture]\n",
    "        model = MyGNN(input_channels=in_channels, mp_layers=[hidden_channels] * num_layers).to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_optimizer(model, optimizer, lr):\n",
    "    \"\"\"Generate optimizer object based on the model and hyperparameters.\"\"\"\n",
    "    if optimizer == \"adam\":\n",
    "        return torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        raise ValueError(\"Only Adam optimizer is currently supported.\")\n",
    "\n",
    "\n",
    "def training_pass(model, batch, optimizer, criterion):\n",
    "    \"\"\"Perofrm a single training pass over the batch.\"\"\"\n",
    "    data = batch.to(device)  # Move to CUDA if available.\n",
    "    out = model.forward(data.x, data.edge_index, batch=data.batch)  # Perform a single forward pass.\n",
    "    loss = criterion(out.squeeze(), data.y)  # Compute the loss.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "\n",
    "def testing_pass(model, batch, criterion):\n",
    "    \"\"\"Perform a single testing pass over the batch.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        data = batch.to(device)\n",
    "        out = model.forward(data.x, data.edge_index, batch=data.batch)\n",
    "        loss = criterion(out.squeeze(), data.y).item()  # Compute the loss.\n",
    "    return loss\n",
    "\n",
    "\n",
    "def do_train(model, data, optimizer, criterion):\n",
    "    \"\"\"Train the model on individual batches or the entire dataset.\"\"\"\n",
    "    model.train()\n",
    "\n",
    "    if isinstance(data, DataLoader):\n",
    "        for batch in data:  # Iterate in batches over the training dataset.\n",
    "            training_pass(model, batch, optimizer, criterion)\n",
    "    elif isinstance(data, Data):\n",
    "        training_pass(model, data, optimizer, criterion)\n",
    "    else:\n",
    "        raise ValueError(\"Data must be a DataLoader or a Batch object.\")\n",
    "\n",
    "\n",
    "def do_test(model, data, criterion):\n",
    "    \"\"\"Test the model on individual batches or the entire dataset.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    if isinstance(data, DataLoader):\n",
    "        for batch in data:\n",
    "            loss = testing_pass(model, batch, criterion)\n",
    "    elif isinstance(data, Data):\n",
    "        loss = testing_pass(model, data, criterion)\n",
    "    else:\n",
    "        raise ValueError(\"Data must be a DataLoader or a Batch object.\")\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train(model, optimizer, criterion, train_data_obj, test_data_obj, num_epochs=100, is_sweep=False):\n",
    "    # GLOBALS: device, dataset, train_data_obj, test_data_obj\n",
    "\n",
    "    # Prepare for training.\n",
    "    train_losses = np.zeros(num_epochs)\n",
    "    test_losses = np.zeros(num_epochs)\n",
    "\n",
    "    # Start the training loop with timer.\n",
    "    training_timer = codetiming.Timer(logger=None)\n",
    "    epoch_timer = codetiming.Timer(logger=None)\n",
    "    training_timer.start()\n",
    "    epoch_timer.start()\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Perform one pass over the training set and then test on both sets.\n",
    "        do_train(model, train_data_obj, optimizer, criterion)\n",
    "        train_loss = do_test(model, train_data_obj, criterion)\n",
    "        test_loss = do_test(model, test_data_obj, criterion)\n",
    "\n",
    "        # Store the losses.\n",
    "        train_losses[epoch - 1] = train_loss\n",
    "        test_losses[epoch - 1] = test_loss\n",
    "        wandb.log({\"train_loss\": train_loss, \"test_loss\": test_loss})\n",
    "\n",
    "        # Print the losses every 10 epochs.\n",
    "        if epoch % 10 == 0 and not is_sweep:\n",
    "            print(\n",
    "                f\"Epoch: {epoch:03d}, \"\n",
    "                f\"Train Loss: {train_loss:.4f}, \"\n",
    "                f\"Test Loss: {test_loss:.4f}, \"\n",
    "                f\"Avg. duration: {epoch_timer.stop() / 10:.4f} s\"\n",
    "            )\n",
    "            epoch_timer.start()\n",
    "    epoch_timer.stop()\n",
    "    duration = training_timer.stop()\n",
    "\n",
    "    results = {\"train_losses\": train_losses, \"test_losses\": test_losses, \"duration\": duration}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from utils import create_graph_wandb, extract_graphs_from_batch, graphs_to_tuple\n",
    "\n",
    "\n",
    "def plot_training_curves(num_epochs, train_losses, test_losses, criterion):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=list(range(1, num_epochs + 1)), y=train_losses, mode=\"lines\", name=\"Train Loss\"))\n",
    "    fig.add_trace(go.Scatter(x=list(range(1, num_epochs + 1)), y=test_losses, mode=\"lines\", name=\"Test Loss\"))\n",
    "    fig.update_layout(title=\"Training and Test Loss\", xaxis_title=\"Epoch\", yaxis_title=criterion)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def eval_batch(model, batch, plot_graphs=False):\n",
    "    # Make predictions.\n",
    "    data = batch.to(device)\n",
    "    out = model(data.x, data.edge_index, data.batch)\n",
    "    predictions = out.cpu().numpy().squeeze()\n",
    "    ground_truth = data.y.cpu().numpy()\n",
    "\n",
    "    # Extract graphs and create visualizations.\n",
    "    nx_graphs = extract_graphs_from_batch(data)\n",
    "    graphs, node_nums, edge_nums = zip(*graphs_to_tuple(nx_graphs))\n",
    "    # FIXME: This is the only way to parallelize in Jupyter but runs out of memory.\n",
    "    # with concurrent.futures.ProcessPoolExecutor(4) as executor:\n",
    "    #     graph_visuals = executor.map(create_graph_wandb, nx_graphs, chunksize=10)\n",
    "    if plot_graphs:\n",
    "        graph_visuals = [create_graph_wandb(g) for g in nx_graphs]\n",
    "    else:\n",
    "        graph_visuals = [\"N/A\"] * len(nx_graphs)\n",
    "\n",
    "    # Store to pandas DataFrame.\n",
    "    return pd.DataFrame(\n",
    "                {\n",
    "                    \"GraphVis\": graph_visuals,\n",
    "                    \"Graph\": graphs,\n",
    "                    \"Nodes\": node_nums,\n",
    "                    \"Edges\": edge_nums,\n",
    "                    \"True\": ground_truth,\n",
    "                    \"Predicted\": predictions,\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "def evaluate(model, test_data, plot_graphs=False, is_sweep=False):\n",
    "    # GLOBALS: dataset_config, train_loader, test_loader\n",
    "\n",
    "    # Evaluate the model on the test set.\n",
    "    model.eval()\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if isinstance(test_data, DataLoader):\n",
    "            for batch in test_data:\n",
    "                df = pd.concat([df, eval_batch(model, batch, plot_graphs)])\n",
    "        elif isinstance(test_data, Data):\n",
    "            df = eval_batch(model, test_data, plot_graphs)\n",
    "        else:\n",
    "            raise ValueError(\"Data must be a DataLoader or a Batch object.\")\n",
    "\n",
    "    # Calculate the statistics.\n",
    "    df[\"Error\"] = df[\"True\"] - df[\"Predicted\"]\n",
    "    df[\"Error %\"] = 100 * df[\"Error\"] / df[\"True\"]\n",
    "    df[\"abs(Error)\"] = np.abs(df[\"Error\"])\n",
    "    err_mean = np.mean(df[\"abs(Error)\"])\n",
    "    err_stddev = np.std(df[\"abs(Error)\"])\n",
    "\n",
    "    # Create a W&B table.\n",
    "    table = wandb.Table(dataframe=df)\n",
    "\n",
    "    # Print and plot.\n",
    "    # df = df.sort_values(by=\"abs(Error)\")\n",
    "    fig_abs_err = px.histogram(df, x=\"Error\")\n",
    "    fig_rel_err = px.histogram(df, x=\"Error %\")\n",
    "\n",
    "    if not is_sweep:\n",
    "        print(f\"Mean error: {err_mean:.4f}\\n\" f\"Std. dev.: {err_stddev:.4f}\\n\")\n",
    "        fig_abs_err.show()\n",
    "        fig_rel_err.show()\n",
    "        df = df.sort_values(by=\"Nodes\")\n",
    "        print(df)\n",
    "\n",
    "    results = {\n",
    "        \"mean_err\": err_mean,\n",
    "        \"stddev_err\": err_stddev,\n",
    "        \"fig_abs_err\": fig_abs_err,\n",
    "        \"fig_rel_err\": fig_rel_err,\n",
    "        \"table\": table,\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config=None, skip_evaluation=False):\n",
    "    # GLOBALS: device\n",
    "\n",
    "    is_sweep = config is None\n",
    "\n",
    "    # Set up dataset.\n",
    "    selected_graph_sizes = {\n",
    "        3: -1,\n",
    "        4: -1,\n",
    "        5: -1,\n",
    "        6: -1,\n",
    "        7: -1,\n",
    "        8: -1,\n",
    "        # 9:  100000,\n",
    "        # 10: 100000\n",
    "    }\n",
    "\n",
    "    # Set up the run\n",
    "    run = wandb.init(mode=\"disabled\", project=\"gnn_fiedler_approx\", tags=[\"lambda2\", \"fiedler\", \"baseline\"], config=config)\n",
    "    config = wandb.config\n",
    "    if is_sweep:\n",
    "        print(f\"Running sweep with config: {config}...\")\n",
    "\n",
    "    # Load the dataset.\n",
    "    train_data_obj, test_data_obj, dataset_config, features = load_dataset(\n",
    "        selected_graph_sizes, selected_features=config.get(\"selected_features\", []), is_sweep=is_sweep\n",
    "    )\n",
    "\n",
    "    wandb.config[\"dataset\"] = dataset_config\n",
    "    if \"selected_features\" not in wandb.config or not wandb.config[\"selected_features\"]:\n",
    "        print(features)\n",
    "        wandb.config[\"selected_features\"] = features\n",
    "        print(wandb.config[\"selected_features\"])\n",
    "\n",
    "    # Set up the model, optimizer, and criterion.\n",
    "    model = generate_model(\n",
    "        config[\"architecture\"],\n",
    "        len(wandb.config[\"selected_features\"]),\n",
    "        config[\"hidden_channels\"],\n",
    "        config[\"num_layers\"],\n",
    "    )\n",
    "    optimizer = generate_optimizer(model, config[\"optimizer\"], config[\"learning_rate\"])\n",
    "    criterion = torch.nn.L1Loss()\n",
    "\n",
    "    # Run training.\n",
    "    train_results = train(\n",
    "        model, optimizer, criterion, train_data_obj, test_data_obj, config[\"epochs\"], is_sweep=is_sweep\n",
    "    )\n",
    "    run.summary[\"best_train_loss\"] = min(train_results[\"train_losses\"])\n",
    "    run.summary[\"best_test_loss\"] = min(train_results[\"test_losses\"])\n",
    "    run.summary[\"duration\"] = train_results[\"duration\"]\n",
    "    if not is_sweep:\n",
    "        plot_training_curves(\n",
    "            config[\"epochs\"], train_results[\"train_losses\"], train_results[\"test_losses\"], type(criterion).__name__\n",
    "        )\n",
    "\n",
    "    # Run evaluation.\n",
    "    if not skip_evaluation:\n",
    "        eval_results = evaluate(model, test_data_obj, plot_graphs=not is_sweep, is_sweep=is_sweep)\n",
    "        run.summary[\"mean_err\"] = eval_results[\"mean_err\"]\n",
    "        run.summary[\"stddev_err\"] = eval_results[\"stddev_err\"]\n",
    "        run.log({\"abs_err_hist\": eval_results[\"fig_abs_err\"], \"rel_err_hist\": eval_results[\"fig_rel_err\"]})\n",
    "        run.log({\"results_table\": eval_results[\"table\"]})\n",
    "\n",
    "    if is_sweep:\n",
    "        print(\n",
    "            f\"    ...DONE. \"\n",
    "            f\"Mean error: {eval_results['mean_err']:.4f}, \"\n",
    "            f\"Std. dev.: {eval_results['stddev_err']:.4f}, \"\n",
    "            f\"Duration: {train_results['duration']:.4f} s.\"\n",
    "        )\n",
    "\n",
    "    return run, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_config = {\n",
    "    \"seed\": 42,\n",
    "    \"architecture\": \"GAT\",\n",
    "    \"hidden_channels\": 10,\n",
    "    \"num_layers\": 3,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 500,\n",
    "}\n",
    "run, model = main(global_config, skip_evaluation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W&B sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env WANDB_SILENT=True\n",
    "\n",
    "import time\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# TODO: How to include seed and dataset configuration?\n",
    "\n",
    "full_sweep_configuration = {\n",
    "    \"name\": \"full_first_sweep\",\n",
    "    \"method\": \"grid\",  # grid, random or Bayesian\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"test_loss\"},\n",
    "    \"parameters\": {\n",
    "        \"architecture\": {\"values\": [\"GCN\", \"GraphSAGE\", \"GIN\", \"GAT\"]},\n",
    "        \"hidden_channels\": {\"values\": [8, 16, 32, 64]},\n",
    "        \"num_layers\": {\"values\": [1, 2, 3, 5]},\n",
    "        \"optimizer\": {\"value\": \"adam\"},\n",
    "        \"learning_rate\": {\"values\": [0.1, 0.01, 0.001]},\n",
    "        \"epochs\": {\"value\": 1000},\n",
    "    },\n",
    "    \"early_terminate\": {\"type\": \"hyperband\", \"eta\": 3, \"min_iter\": 300},\n",
    "}\n",
    "\n",
    "test_sweep_configuration = {\n",
    "    \"name\": \"test_sweep\",\n",
    "    \"method\": \"grid\",  # grid, random or Bayesian\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"test_loss\"},\n",
    "    \"parameters\": {\n",
    "        \"architecture\": {\"values\": [\"GAT\"]},\n",
    "        \"hidden_channels\": {\"values\": [16]},\n",
    "        \"num_layers\": {\"values\": [3]},\n",
    "        \"selected_features\": {\"values\": [\n",
    "            [],\n",
    "            [\"degree\"],\n",
    "            [\"degree\", \"degree_centrality\"],\n",
    "        ]},\n",
    "        \"optimizer\": {\"value\": \"adam\"},\n",
    "        \"learning_rate\": {\"values\": [0.01]},\n",
    "        \"epochs\": {\"value\": 1000},\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=test_sweep_configuration, project=\"gnn_fiedler_approx\")\n",
    "\n",
    "wandb.agent(sweep_id, function=main, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the W&B run.\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer, PGExplainer, AttentionExplainer\n",
    "\n",
    "train_data_obj, test_data_obj, dataset_config, features = load_dataset(None, batch_size=1, is_sweep=True)\n",
    "# model = generate_model(\"GraphSAGE\", len(features), 10, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GNNExplainer for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Are these results ok?\n",
    "# Seems like the results are different on every run. Plus, how to interpret the\n",
    "# results? What hyperparaters to use?\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=200),  # PGExplainer, AttentionExplainer, CaptumExplainer\n",
    "    # explanation_type='phenomenon',  # what phenomenon leads from inputs to outputs, labels are targets for explanation\n",
    "    explanation_type='model',  # open the black box and explain model decisions, predictions are targets for explanation\n",
    "    node_mask_type=\"attributes\",  # \"object\", \"common_attributes\", \"attributes\"\n",
    "    edge_mask_type=\"object\",\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='graph',\n",
    "        return_type='raw',\n",
    "    )\n",
    ")\n",
    "\n",
    "data = train_data_obj.to(device)\n",
    "explanation = explainer(data.x, data.edge_index, batch=data.batch)\n",
    "for exp in explanation.available_explanations:\n",
    "    print(f\"{exp}:\\n{explanation.__getattr__(exp)}\\n\")\n",
    "\n",
    "explanation.visualize_feature_importance(feat_labels=features)\n",
    "explanation.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GNNExplainer for phenomenon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Are these results ok?\n",
    "# Seems like the results are different on every run. Plus, how to interpret the\n",
    "# results? What hyperparaters to use?\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=200),  # PGExplainer, AttentionExplainer, CaptumExplainer\n",
    "    explanation_type='phenomenon',  # what phenomenon leads from inputs to outputs, labels are targets for explanation\n",
    "    # explanation_type='model',  # open the black box and explain model decisions, predictions are targets for explanation\n",
    "    node_mask_type=\"attributes\",  # \"object\", \"common_attributes\", \"attributes\"\n",
    "    edge_mask_type=\"object\",\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='graph',\n",
    "        return_type='raw',\n",
    "    )\n",
    ")\n",
    "\n",
    "data = train_data_obj.to(device)\n",
    "explanation = explainer(data.x, data.edge_index, target=data.y, batch=data.batch)\n",
    "for exp in explanation.available_explanations:\n",
    "    print(f\"{exp}:\\n{explanation.__getattr__(exp)}\\n\")\n",
    "\n",
    "explanation.visualize_feature_importance(feat_labels=features)\n",
    "explanation.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AttentionExplainer for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Are these results ok?\n",
    "# Seems like the results are different on every run. Plus, how to interpret the\n",
    "# results? What hyperparaters to use?\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=AttentionExplainer(),  # PGExplainer, AttentionExplainer, CaptumExplainer\n",
    "    # explanation_type='phenomenon',  # what phenomenon leads from inputs to outputs, labels are targets for explanation\n",
    "    explanation_type='model',  # open the black box and explain model decisions, predictions are targets for explanation\n",
    "    node_mask_type=None,  # \"object\", \"common_attributes\", \"attributes\"\n",
    "    edge_mask_type=\"object\",\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='graph',\n",
    "        return_type='raw',\n",
    "    )\n",
    ")\n",
    "\n",
    "data = train_data_obj.to(device)\n",
    "explanation = explainer(data.x, data.edge_index, batch=data.batch)\n",
    "for exp in explanation.available_explanations:\n",
    "    print(f\"{exp}:\\n{explanation.__getattr__(exp)}\\n\")\n",
    "\n",
    "# explanation.visualize_feature_importance(feat_labels=features)\n",
    "explanation.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PGEExplainer - WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: Something is wrong with the implementation.\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=PGExplainer(epochs=30, lr=0.003),  # PGExplainer, AttentionExplainer, CaptumExplainer\n",
    "    explanation_type='phenomenon',  # what phenomenon leads from inputs to outputs, labels are targets for explanation\n",
    "    # explanation_type='model',  # open the black box and explain model decisions, predictions are targets for explanation\n",
    "    # node_mask_type=\"common_attributes\",  # Node masks are not supported.\n",
    "    edge_mask_type=\"object\",\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='graph',\n",
    "        return_type='raw',\n",
    "    )\n",
    ")\n",
    "\n",
    "data = train_data_obj.to(device)\n",
    "\n",
    "for epoch in range(30):\n",
    "  for index in torch.LongTensor(np.random.randint(0, len(data.x), 20)):\n",
    "    loss = explainer.algorithm.train(epoch, model, data.x, data.edge_index, target=data.y, batch=data.batch, index=index.item())\n",
    "\n",
    "explanation = explainer(data.x, data.edge_index, target=data.y, batch=data.batch)\n",
    "\n",
    "for exp in explanation.available_explanations:\n",
    "    print(f\"{exp}:\\n{explanation.__getattr__(exp)}\\n\")\n",
    "\n",
    "# explanation.visualize_feature_importance(feat_labels=features)\n",
    "explanation.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"model.pth\")\n",
    "# print(\"Saved PyTorch Model State to model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions with loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NeuralNetwork().to(device)\n",
    "# model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "# classes = [\n",
    "#     \"T-shirt/top\",\n",
    "#     \"Trouser\",\n",
    "#     \"Pullover\",\n",
    "#     \"Dress\",\n",
    "#     \"Coat\",\n",
    "#     \"Sandal\",\n",
    "#     \"Shirt\",\n",
    "#     \"Sneaker\",\n",
    "#     \"Bag\",\n",
    "#     \"Ankle boot\",\n",
    "# ]\n",
    "\n",
    "# model.eval()\n",
    "# x, y = test_data[0][0], test_data[0][1]\n",
    "# with torch.no_grad():\n",
    "#     x = x.to(device)\n",
    "#     pred = model(x)\n",
    "#     predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "#     print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional W&B APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api = wandb.Api()\n",
    "\n",
    "# # Access attributes directly from the run object\n",
    "# # or from the W&B App\n",
    "# username = \"marko-krizmancic\"\n",
    "# project = \"gnn_fiedler_approx\"\n",
    "# run_id = [\"nrcdc1y4\", \"11l94b1a\", \"ptj7b0vx\"]\n",
    "\n",
    "# for id in run_id:\n",
    "#     run = api.run(f\"{username}/{project}/{id}\")\n",
    "#     run.config[\"model\"] = \"GCN\"\n",
    "#     run.update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
