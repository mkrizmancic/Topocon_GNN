{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9019ebe",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bae8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "# pio.templates.default = \"plotly_white\"\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.precision = 2\n",
    "\n",
    "results_root = pathlib.Path(\"../results/\")\n",
    "\n",
    "all_stats_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95211d5",
   "metadata": {},
   "source": [
    "# Load the csv file with results into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be901e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep = \"broad_sweep\"\n",
    "# boxplots_to_save = [\"architecture\"]\n",
    "# interaction_plots_to_save = [\n",
    "#     (\"architecture\", \"gnn_layers\"),\n",
    "#     (\"architecture\", \"mlp_layers\"),\n",
    "#     (\"architecture\", \"hidden_channels\"),\n",
    "#     (\"architecture\", \"pool\"),\n",
    "# ]\n",
    "\n",
    "# sweep = \"jk_pooling_sweep\"\n",
    "# boxplots_to_save = [\"pool\"]\n",
    "# interaction_plots_to_save = [\n",
    "#     (\"pool\", \"architecture\")\n",
    "# ]\n",
    "\n",
    "sweep = \"regularizing_sweep\"\n",
    "boxplots_to_save = []\n",
    "interaction_plots_to_save = [\n",
    "    (\"norm\", \"transform\")\n",
    "]\n",
    "\n",
    "# sweep = \"relaxed\"\n",
    "\n",
    "df = pd.read_csv(results_root / \"runs_data\" / f\"{sweep}.csv\")\n",
    "df.head()\n",
    "\n",
    "df = df.fillna(value=\"none\")\n",
    "df = df.rename(columns={\"good_within.99\": \"≤ 1% error\", \"good_within.95\": \"≤ 5% error\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4144872d",
   "metadata": {},
   "source": [
    "# Draw boxplots to compare hyperparameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6253ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "hyperparameters = [\"architecture\", \"gnn_layers\", \"mlp_layers\", \"hidden_channels\", \"jk\", \"pool\", \"activation\", \"norm\", \"transform\", \"dropout\", \"selected_features\"]\n",
    "metrics_to_plot = [\"≤ 1% error\", \"≤ 5% error\"]\n",
    "\n",
    "\n",
    "if \"selected_features\" in df.columns:\n",
    "    df[\"selected_features\"] = df[\"selected_features\"].apply(lambda x: \"original\" if \"core_number\" in x else \"new\")\n",
    "\n",
    "for hyperparameter in hyperparameters:\n",
    "    # Create a temporary dataframe for plotting, dropping rows where the hyperparameter is null\n",
    "    plot_df = df\n",
    "\n",
    "    # Filter out some values\n",
    "    # plot_df = plot_df[~plot_df[\"pool\"].isin([\"median\"])]\n",
    "    # # plot_df = plot_df[plot_df[\"gnn_layers\"] == 5]\n",
    "    # plot_df = plot_df[plot_df[\"hidden_channels\"] == 64]\n",
    "\n",
    "    # Get the actual categories present in the data\n",
    "    actual_categories = sorted(plot_df[hyperparameter].unique())\n",
    "\n",
    "    # Create subplots\n",
    "    fig_to_show = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=(f\"Accuracy vs. {hyperparameter}\", f\"Training duration vs {hyperparameter}\"),\n",
    "        horizontal_spacing=0.1\n",
    "    )\n",
    "    fig_to_save = go.Figure()\n",
    "\n",
    "    # Add main metrics to left subplot\n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        trace = go.Box(x=plot_df[hyperparameter], y=plot_df[metric],\n",
    "                       name=metric, boxmean=True,\n",
    "                       marker_color=px.colors.qualitative.Plotly[i],\n",
    "                       offsetgroup=str(i))\n",
    "        fig_to_show.add_trace(trace, row=1, col=1)\n",
    "        fig_to_save.add_trace(trace)\n",
    "\n",
    "    # Add duration metric to right subplot\n",
    "    fig_to_show.add_trace(\n",
    "        go.Box(x=plot_df[hyperparameter], y=plot_df['duration'],\n",
    "               name='duration', boxmean=True,\n",
    "               marker_color=px.colors.qualitative.Plotly[2],\n",
    "               showlegend=False,\n",
    "               offsetgroup='duration',\n",
    "               width=0.6),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # Update layout for both subplots on the showing figure\n",
    "    fig_to_show.update_xaxes(\n",
    "        type='category',\n",
    "        categoryorder='array',\n",
    "        categoryarray=actual_categories,\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig_to_show.update_xaxes(\n",
    "        type='category',\n",
    "        categoryorder='array',\n",
    "        categoryarray=actual_categories,\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig_to_show.update_yaxes(title_text=\"% of graphs within error\", row=1, col=1)\n",
    "    fig_to_show.update_yaxes(title_text=\"Duration (s)\", row=1, col=2)\n",
    "\n",
    "    fig_to_show.update_layout(\n",
    "        height=400,\n",
    "        margin=dict(l=20, r=20, t=20, b=20),\n",
    "        boxmode='group',\n",
    "        boxgap=0.2,\n",
    "        boxgroupgap=0.1\n",
    "    )\n",
    "    fig_to_show.show()\n",
    "\n",
    "    # Update layout for the saving figure\n",
    "    fig_to_save.update_xaxes(\n",
    "        type='category',\n",
    "        categoryorder='array',\n",
    "        categoryarray=actual_categories,\n",
    "    )\n",
    "    fig_to_save.update_yaxes(title_text=\"% of graphs within error\")\n",
    "    fig_to_save.update_layout(\n",
    "        height=600,\n",
    "        width=800,\n",
    "        margin=dict(l=5, r=5, t=5, b=5),\n",
    "        font=dict(size=20),\n",
    "        boxmode='group',\n",
    "        boxgap=0.2,\n",
    "        boxgroupgap=0.1,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"right\",\n",
    "            x=1,\n",
    "        ),\n",
    "        # template=\"plotly_white\"\n",
    "    )\n",
    "\n",
    "    if hyperparameter in boxplots_to_save:\n",
    "        file_path = results_root / \"boxplots\"\n",
    "        file_path.mkdir(parents=True, exist_ok=True)\n",
    "        fig_to_save.write_image(file_path / f\"{sweep}_{hyperparameter}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc04c738",
   "metadata": {},
   "source": [
    "# Best model for specified hyperparameter value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = \"selected_features\"\n",
    "metric = \"≤ 1% error\"\n",
    "\n",
    "best_runs = df.loc[df.groupby(hyperparameter)[metric].idxmax()]\n",
    "best_runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036d8be7",
   "metadata": {},
   "source": [
    "# Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df = df.rename(columns={\"≤ 1% error\": \"Accuracy\"})\n",
    "stat_df = stat_df[hyperparameters + [\"Accuracy\"]]\n",
    "stat_df = stat_df[[col for col in stat_df.columns if stat_df[col].nunique() > 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8c03a",
   "metadata": {},
   "source": [
    "## Paired comparison of effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dbc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "def bootstrap_ci(data, n_bootstrap=5000, ci=95, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    boot_means = [rng.choice(data, size=len(data), replace=True).mean() for _ in range(n_bootstrap)]\n",
    "    lower = np.percentile(boot_means, (100-ci)/2)\n",
    "    upper = np.percentile(boot_means, 100-(100-ci)/2)\n",
    "    return lower, upper\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for hyperparam in [c for c in stat_df.columns if c != \"Accuracy\"]:\n",
    "    values = stat_df[hyperparam].unique()\n",
    "    for a, b in itertools.combinations(values, 2):\n",
    "        mask_a = stat_df[hyperparam] == a\n",
    "        mask_b = stat_df[hyperparam] == b\n",
    "        merged = stat_df[mask_a].merge(\n",
    "            stat_df[mask_b],\n",
    "            on=[c for c in stat_df.columns if c not in [hyperparam, \"Accuracy\"]],\n",
    "            suffixes=(f\"_{a}\", f\"_{b}\")\n",
    "        )\n",
    "        if merged.empty:\n",
    "            continue\n",
    "        diff = merged[f\"Accuracy_{a}\"] - merged[f\"Accuracy_{b}\"]\n",
    "\n",
    "        mean_diff = diff.mean()\n",
    "        median_diff = diff.median()\n",
    "        std_diff = diff.std()\n",
    "        ci_low, ci_high = bootstrap_ci(diff.values)\n",
    "        # effect size: rank-biserial correlation\n",
    "        effect_size = (np.sum(diff > 0) - np.sum(diff < 0)) / len(diff)\n",
    "\n",
    "        # Wilcoxon test\n",
    "        stat, pval = wilcoxon(diff)\n",
    "\n",
    "        all_results.append({\n",
    "            \"hyperparam\": hyperparam,\n",
    "            \"comparison\": f\"{a} vs {b}\",\n",
    "            \"mean_diff\": mean_diff,\n",
    "            \"median_diff\": median_diff,\n",
    "            \"std_diff\": std_diff,\n",
    "            \"ci\": [round(ci_low, 2), round(ci_high, 2)],\n",
    "            \"effect_size\": effect_size,\n",
    "            \"pval\": pval\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Apply Holm correction separately within each hyperparameter\n",
    "results_df[\"pval_holm\"] = results_df.groupby(\"hyperparam\")[\"pval\"].transform(\n",
    "    lambda p: multipletests(p, method=\"holm\")[1]\n",
    ")\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "# all_stats_df = pd.concat([all_stats_df, results_df], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c374457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataframe(df, sci_cols):\n",
    "    df_formatted = df.copy()\n",
    "    for col in df_formatted.columns:\n",
    "        if col in sci_cols:\n",
    "            df_formatted[col] = df_formatted[col].map(lambda x: f'{x:.2e}' if pd.notnull(x) else x)\n",
    "        elif pd.api.types.is_numeric_dtype(df_formatted[col]):\n",
    "            df_formatted[col] = df_formatted[col].map(lambda x: f'{x:.2f}' if pd.notnull(x) else x)\n",
    "    return df_formatted\n",
    "\n",
    "# all_stats_df = format_dataframe(all_stats_df, sci_cols=['pval', 'pval_holm'])\n",
    "# all_stats_df.to_csv(\"../results/hyper_search_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7cda5",
   "metadata": {},
   "source": [
    "## Importance of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d34818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from itertools import combinations\n",
    "\n",
    "main_effects = [c for c in stat_df.columns if c != \"Accuracy\"]\n",
    "interaction_terms = [f\"{a}*{b}\" for a, b in combinations(main_effects, 2)]\n",
    "\n",
    "formula = \"Accuracy ~ \" + \" + \".join(main_effects + interaction_terms)\n",
    "model = smf.ols(formula, data=stat_df).fit()\n",
    "\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table[\"eta_sq\"] = anova_table[\"sum_sq\"] / anova_table[\"sum_sq\"].sum()\n",
    "anova_table = anova_table.sort_values(by=[\"eta_sq\"], ascending=False)\n",
    "\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f270c9d",
   "metadata": {},
   "source": [
    "## Interaction plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6592c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_interaction_grid(df, params, response=\"Accuracy\"):\n",
    "    pairs = list(itertools.combinations(params, 2))\n",
    "    n = len(pairs)\n",
    "    ncols = 3  # how many plots per row\n",
    "    nrows = -(-n // ncols)  # ceil division\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(5*ncols, 4*nrows), squeeze=False)\n",
    "\n",
    "    for ax, (p1, p2) in zip(axes.flatten(), pairs):\n",
    "        sns.pointplot(\n",
    "            data=df, x=p1, y=response, hue=p2,\n",
    "            dodge=True, markers=\"o\", capsize=0.1, errorbar=\"pi\", ax=ax  # pi = percentile interval\n",
    "        )\n",
    "        ax.set_title(f\"{p1} × {p2}\")\n",
    "        ax.legend(title=p2, fontsize=\"small\", title_fontsize=\"small\")\n",
    "\n",
    "    # Remove empty subplots if any\n",
    "    for ax in axes.flatten()[len(pairs):]:\n",
    "        ax.remove()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "params = [c for c in stat_df.columns if c != \"Accuracy\"]\n",
    "plot_interaction_grid(stat_df, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89021831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.colors\n",
    "\n",
    "def save_interaction_plot(df, factor1, factor2, response, results_root, sweep):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    if not factor1 or not factor2 or factor1 not in df.columns or factor2 not in df.columns:\n",
    "        return\n",
    "\n",
    "    # Get unique values for factors\n",
    "    x_categories = sorted(df[factor1].unique())\n",
    "    hue_values = sorted(df[factor2].unique())\n",
    "\n",
    "    # --- COLOR LOGIC ---\n",
    "    is_hue_numeric = pd.api.types.is_numeric_dtype(df[factor2])\n",
    "    if is_hue_numeric:\n",
    "        hue_min, hue_max = df[factor2].min(), df[factor2].max()\n",
    "\n",
    "        color_map = {}\n",
    "        for value in hue_values:\n",
    "            if hue_min == hue_max:\n",
    "                norm_val = 0.5\n",
    "            else:\n",
    "                norm_val = (value - hue_min) / (hue_max - hue_min)\n",
    "            color_map[value] = plotly.colors.sample_colorscale('burg', norm_val)[0]\n",
    "    else:\n",
    "        qualitative_colors = px.colors.qualitative.Plotly\n",
    "        color_map = {hue: qualitative_colors[i % len(qualitative_colors)] for i, hue in enumerate(hue_values)}\n",
    "    # --- END COLOR LOGIC ---\n",
    "\n",
    "    # Define an offset for dodging\n",
    "    num_hues = len(hue_values)\n",
    "    offset_width = 0.05\n",
    "    offsets = np.linspace(0, offset_width * num_hues, num_hues) if num_hues > 1 else [0]\n",
    "\n",
    "    # Create traces for each hue value\n",
    "    for i, hue in enumerate(hue_values):\n",
    "        means = []\n",
    "        errors = []\n",
    "\n",
    "        x_numeric = np.arange(len(x_categories))\n",
    "        x_offset = x_numeric + offsets[i]\n",
    "\n",
    "        for cat in x_categories:\n",
    "            subset = df[(df[factor1] == cat) & (df[factor2] == hue)]\n",
    "            if not subset.empty:\n",
    "                mean = subset[response].mean()\n",
    "                means.append(mean)\n",
    "                lower, upper = np.percentile(subset[response], [2.5, 97.5])\n",
    "                errors.append(dict(upper=upper - mean, lower=mean - lower))\n",
    "            else:\n",
    "                means.append(None)\n",
    "                errors.append(dict(upper=0, lower=0))\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x_offset,\n",
    "            y=means,\n",
    "            mode='lines+markers',\n",
    "            name=str(hue),\n",
    "            line=dict(width=3, color=color_map[hue]),\n",
    "            marker=dict(size=10, color=color_map[hue]),\n",
    "            error_y=dict(\n",
    "                type='data',\n",
    "                symmetric=False,\n",
    "                array=[e['upper'] for e in errors],\n",
    "                arrayminus=[e['lower'] for e in errors],\n",
    "                visible=True,\n",
    "                width=7,\n",
    "                thickness=3,\n",
    "            )\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=factor1,\n",
    "        yaxis_title=response,\n",
    "        height=600,\n",
    "        width=800,\n",
    "        margin=dict(l=5, r=5, t=40, b=70),\n",
    "        font=dict(size=20),\n",
    "        xaxis=dict(\n",
    "            tickmode='array',\n",
    "            tickvals=np.arange(len(x_categories)),\n",
    "            ticktext=x_categories\n",
    "        ),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"right\",\n",
    "            x=1,\n",
    "            title=factor2\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    image_path = results_root / \"interaction_plots\"\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    image_path /= f\"{sweep}_{factor1}_{factor2}.pdf\"\n",
    "    fig.write_image(image_path)\n",
    "\n",
    "\n",
    "# Replace the old function call\n",
    "for factor1, factor2 in interaction_plots_to_save:\n",
    "    save_interaction_plot(stat_df, factor1, factor2, \"Accuracy\", results_root, sweep)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphs_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
