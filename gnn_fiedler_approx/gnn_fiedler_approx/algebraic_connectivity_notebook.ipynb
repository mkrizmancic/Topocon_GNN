{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Loaded torch. Using *{device}* device.\")\n",
    "\n",
    "__builtins__.device = device  # A hack to allow imported functions to use the device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration.\n",
    "config = {\n",
    "    ## Model configuration\n",
    "    \"architecture\": \"GraphSAGE\",\n",
    "    \"hidden_channels\": 32,\n",
    "    \"gnn_layers\": 5,\n",
    "    \"mlp_layers\": 2,\n",
    "    \"activation\": \"tanh\",\n",
    "    \"pool\": \"max\",\n",
    "    \"jk\": \"cat\",\n",
    "    \"dropout\": 0.0,\n",
    "    ## Training configuration\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 2000,\n",
    "    ## Dataset configuration\n",
    "}\n",
    "\n",
    "# Set up default values.\n",
    "selected_graph_sizes = {\n",
    "    3: -1,\n",
    "    4: -1,\n",
    "    5: -1,\n",
    "    6: -1,\n",
    "    7: -1,\n",
    "    8: -1,\n",
    "    # 9:  100000,\n",
    "    # 10: 100000\n",
    "}\n",
    "\n",
    "# Set up the run\n",
    "run = wandb.init(mode=\"disabled\", project=\"gnn_fiedler_approx\", tags=[\"lambda2\", \"baseline\"], config=config)\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algebraic_connectivity_script import load_dataset\n",
    "\n",
    "# Load the dataset.\n",
    "train_data_obj, test_data_obj, dataset_config, features, dataset_props = load_dataset(\n",
    "        selected_graph_sizes,\n",
    "        selected_features=config.get(\"selected_features\", []),\n",
    "        label_normalization=None,\n",
    "        split=config.get(\"dataset\", {}).get(\"split\", 0.8),\n",
    "    )\n",
    "\n",
    "wandb.config[\"dataset\"] = dataset_config\n",
    "if \"selected_features\" not in wandb.config or not wandb.config[\"selected_features\"]:\n",
    "    wandb.config[\"selected_features\"] = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algebraic_connectivity_script import generate_model, generate_optimizer\n",
    "\n",
    "model_kwargs = config.get(\"model_kwargs\", {})\n",
    "\n",
    "model = generate_model(\n",
    "    config[\"architecture\"],\n",
    "    dataset_props[\"feature_dim\"],\n",
    "    config[\"hidden_channels\"],\n",
    "    config[\"gnn_layers\"],\n",
    "    mlp_layers=config[\"mlp_layers\"],\n",
    "    act=config[\"activation\"],\n",
    "    dropout=float(config[\"dropout\"]),\n",
    "    pool=config[\"pool\"],\n",
    "    jk=config[\"jk\"] if config[\"jk\"] != \"none\" else None,\n",
    "    **model_kwargs,\n",
    ")\n",
    "optimizer = generate_optimizer(model, config[\"optimizer\"], config[\"learning_rate\"])\n",
    "criterion = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algebraic_connectivity_script import train, plot_training_curves\n",
    "\n",
    "# Run training.\n",
    "train_results = train(\n",
    "    model, optimizer, criterion, train_data_obj, test_data_obj, config[\"epochs\"], save_best=True\n",
    ")\n",
    "run.summary[\"best_train_loss\"] = min(train_results[\"train_losses\"])\n",
    "run.summary[\"best_test_loss\"] = min(train_results[\"test_losses\"])\n",
    "run.summary[\"duration\"] = train_results[\"duration\"]\n",
    "plot_training_curves(\n",
    "    config[\"epochs\"], train_results[\"train_losses\"], train_results[\"test_losses\"], type(criterion).__name__\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "from algebraic_connectivity_script import BEST_MODEL_PATH\n",
    "\n",
    "checkpoint = torch.load(BEST_MODEL_PATH)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "eval_epoch = checkpoint[\"epoch\"]\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algebraic_connectivity_script import evaluate\n",
    "\n",
    "eval_results = evaluate(\n",
    "            model, eval_epoch, criterion, train_data_obj, test_data_obj, dataset_props[\"transformation\"],\n",
    "        )\n",
    "run.summary[\"mean_err\"] = eval_results[\"mean_err\"]\n",
    "run.summary[\"stddev_err\"] = eval_results[\"stddev_err\"]\n",
    "run.summary[\"good_within\"] = eval_results[\"good_within\"]\n",
    "run.log(\n",
    "    {\n",
    "        \"abs_err_hist\": eval_results[\"fig_abs_err\"],\n",
    "        \"rel_err_hist\": eval_results[\"fig_rel_err\"],\n",
    "        \"err_curve\": eval_results[\"fig_err_curve\"],\n",
    "    }\n",
    ")\n",
    "# run.log({\"results_table\": eval_results[\"table\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the W&B run.\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer, PGExplainer, AttentionExplainer\n",
    "\n",
    "train_data_obj, test_data_obj, dataset_config, features = load_dataset(None, batch_size=1, is_sweep=True)\n",
    "# model = generate_model(\"GCN\", len(features), 10, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GNNExplainer for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Are these results ok?\n",
    "# Seems like the results are different on every run. Plus, how to interpret the\n",
    "# results? What hyperparaters to use?\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=200),  # PGExplainer, AttentionExplainer, CaptumExplainer\n",
    "    # explanation_type='phenomenon',  # what phenomenon leads from inputs to outputs, labels are targets for explanation\n",
    "    explanation_type='model',  # open the black box and explain model decisions, predictions are targets for explanation\n",
    "    node_mask_type=\"attributes\",  # \"object\", \"common_attributes\", \"attributes\"\n",
    "    edge_mask_type=\"object\",\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='graph',\n",
    "        return_type='raw',\n",
    "    )\n",
    ")\n",
    "\n",
    "data = train_data_obj.to(device)\n",
    "explanation = explainer(data.x, data.edge_index, batch=data.batch)\n",
    "for exp in explanation.available_explanations:\n",
    "    print(f\"{exp}:\\n{explanation.__getattr__(exp)}\\n\")\n",
    "\n",
    "explanation.visualize_feature_importance(feat_labels=features)\n",
    "explanation.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GNNExplainer for phenomenon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Are these results ok?\n",
    "# Seems like the results are different on every run. Plus, how to interpret the\n",
    "# results? What hyperparaters to use?\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=200),  # PGExplainer, AttentionExplainer, CaptumExplainer\n",
    "    explanation_type='phenomenon',  # what phenomenon leads from inputs to outputs, labels are targets for explanation\n",
    "    # explanation_type='model',  # open the black box and explain model decisions, predictions are targets for explanation\n",
    "    node_mask_type=\"attributes\",  # \"object\", \"common_attributes\", \"attributes\"\n",
    "    edge_mask_type=\"object\",\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='graph',\n",
    "        return_type='raw',\n",
    "    )\n",
    ")\n",
    "\n",
    "data = train_data_obj.to(device)\n",
    "explanation = explainer(data.x, data.edge_index, target=data.y, batch=data.batch)\n",
    "for exp in explanation.available_explanations:\n",
    "    print(f\"{exp}:\\n{explanation.__getattr__(exp)}\\n\")\n",
    "\n",
    "explanation.visualize_feature_importance(feat_labels=features)\n",
    "explanation.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AttentionExplainer for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Are these results ok?\n",
    "# Seems like the results are different on every run. Plus, how to interpret the\n",
    "# results? What hyperparaters to use?\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=AttentionExplainer(),  # PGExplainer, AttentionExplainer, CaptumExplainer\n",
    "    # explanation_type='phenomenon',  # what phenomenon leads from inputs to outputs, labels are targets for explanation\n",
    "    explanation_type='model',  # open the black box and explain model decisions, predictions are targets for explanation\n",
    "    node_mask_type=None,  # \"object\", \"common_attributes\", \"attributes\"\n",
    "    edge_mask_type=\"object\",\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='graph',\n",
    "        return_type='raw',\n",
    "    )\n",
    ")\n",
    "\n",
    "data = train_data_obj.to(device)\n",
    "explanation = explainer(data.x, data.edge_index, batch=data.batch)\n",
    "for exp in explanation.available_explanations:\n",
    "    print(f\"{exp}:\\n{explanation.__getattr__(exp)}\\n\")\n",
    "\n",
    "# explanation.visualize_feature_importance(feat_labels=features)\n",
    "explanation.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PGEExplainer - WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: Something is wrong with the implementation.\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=PGExplainer(epochs=30, lr=0.003),  # PGExplainer, AttentionExplainer, CaptumExplainer\n",
    "    explanation_type='phenomenon',  # what phenomenon leads from inputs to outputs, labels are targets for explanation\n",
    "    # explanation_type='model',  # open the black box and explain model decisions, predictions are targets for explanation\n",
    "    # node_mask_type=\"common_attributes\",  # Node masks are not supported.\n",
    "    edge_mask_type=\"object\",\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='graph',\n",
    "        return_type='raw',\n",
    "    )\n",
    ")\n",
    "\n",
    "data = train_data_obj.to(device)\n",
    "\n",
    "for epoch in range(30):\n",
    "  for index in torch.LongTensor(np.random.randint(0, len(data.x), 20)):\n",
    "    loss = explainer.algorithm.train(epoch, model, data.x, data.edge_index, target=data.y, batch=data.batch, index=index.item())\n",
    "\n",
    "explanation = explainer(data.x, data.edge_index, target=data.y, batch=data.batch)\n",
    "\n",
    "for exp in explanation.available_explanations:\n",
    "    print(f\"{exp}:\\n{explanation.__getattr__(exp)}\\n\")\n",
    "\n",
    "# explanation.visualize_feature_importance(feat_labels=features)\n",
    "explanation.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"model.pth\")\n",
    "# print(\"Saved PyTorch Model State to model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions with loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NeuralNetwork().to(device)\n",
    "# model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "# classes = [\n",
    "#     \"T-shirt/top\",\n",
    "#     \"Trouser\",\n",
    "#     \"Pullover\",\n",
    "#     \"Dress\",\n",
    "#     \"Coat\",\n",
    "#     \"Sandal\",\n",
    "#     \"Shirt\",\n",
    "#     \"Sneaker\",\n",
    "#     \"Bag\",\n",
    "#     \"Ankle boot\",\n",
    "# ]\n",
    "\n",
    "# model.eval()\n",
    "# x, y = test_data[0][0], test_data[0][1]\n",
    "# with torch.no_grad():\n",
    "#     x = x.to(device)\n",
    "#     pred = model(x)\n",
    "#     predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "#     print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional W&B APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api = wandb.Api()\n",
    "\n",
    "# # Access attributes directly from the run object\n",
    "# # or from the W&B App\n",
    "# username = \"marko-krizmancic\"\n",
    "# project = \"gnn_fiedler_approx\"\n",
    "# run_id = [\"nrcdc1y4\", \"11l94b1a\", \"ptj7b0vx\"]\n",
    "\n",
    "# for id in run_id:\n",
    "#     run = api.run(f\"{username}/{project}/{id}\")\n",
    "#     run.config[\"model\"] = \"GCN\"\n",
    "#     run.update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphs_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
